Generative artificial intelligence, in particular through the use of large language models (LLMs), is playing an increasingly important role in everyday life, offering advanced tools for the automated generation of text, also as a response to descriptive and predictive tasks and for the execution of logical-mathematical tasks of varying complexity. However, the large-scale diffusion of these models raises questions regarding the security of the answers provided with respect to the possible legal implications they may have.
The aim of this thesis is to analyse the effectiveness of prompt engineering techniques in mitigating the risk of generating content that does not comply with current regulations (or is inappropriate from a social point of view). To this end, the generated responses will be classified into four categories, differentiated according to their content and level of legal compliance. Subsequently, approaches will be adopted to evaluate the responses to the various questions as the prompt engineering techniques vary. The results obtained may contribute to the development of solutions aimed at making the user more aware of the possible legal implications of the responses produced by LLMs, for a safer and more responsible use of LLMs, promoting the adoption of effective strategies for mitigating the risks associated with generative artificial intelligence.